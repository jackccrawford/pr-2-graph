# pr-2-graph Configuration Template
# Copy to .env.local and customize for your environment

# Server Settings
PORT=7700
HOST=0.0.0.0
DEBUG=true

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_TIMEOUT=300

# Model Configuration
PRIMARY_MODEL=gemma3n:e2b
CRITIC_MODEL=qwen3:1.7b
EMBEDDINGS_MODEL=nomic-embed-text
FALLBACK_MODEL=qwen2.5:latest
FORMATTER_MODEL=phi4-mini:3.8b

# Memory Management
MAX_MEMORY_GB=12
AUTO_CLEANUP=true
FALLBACK_THRESHOLD=0.3

# Analysis Settings
ENABLE_CRITIQUE=true
ENABLE_EMBEDDINGS=true
ANALYSIS_TIMEOUT=120

# GitHub API (optional)
# GITHUB_TOKEN=your_token_here
GITHUB_API_URL=https://api.github.com

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json
